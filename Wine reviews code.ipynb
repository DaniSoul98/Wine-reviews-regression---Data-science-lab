{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('dev.tsv', sep='\\t')\n",
    "df_dev.drop_duplicates(inplace = True)\n",
    "df_dev=df_dev[df_dev['quality']>=0]\n",
    "\n",
    "df_eval = pd.read_csv('eval.tsv', sep='\\t')\n",
    "\n",
    "df = pd.concat([df_dev, df_eval], sort=False, ignore_index=True)\n",
    "len(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_values_dev = len(df_dev)-len(df_dev.drop_duplicates()), \n",
    "# missing_values_eval = len(df_eval)-len(df_eval.drop_duplicates()), \n",
    "# missing_values_df = len(df)-len(df.drop_duplicates())\n",
    "\n",
    "# missing_values_dev, missing_values_eval, missing_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 38311-35716"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_dev.drop('quality', axis=1).columns\n",
    "x = df_dev.drop('quality', axis=1).isnull().sum()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.set(rc={'figure.figsize':(6,4)})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.5) \n",
    "\n",
    "ax.set(xlabel='Number of missing values')\n",
    "ax.set(ylabel='Features')\n",
    "ax.set_xlim(0,85000)\n",
    "ax.set_xticks(np.arange(0,86000,15000))\n",
    "\n",
    "ax = sns.barplot(x=x, y=y, color=\"cornflowerblue\", saturation=1)#.set_title('Null values')\n",
    "#fig.savefig(\"missingValues2.pdf\",bbox_inches='tight')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(df_dev['quality'], kde=True)\n",
    "mean = df_dev['quality'].mean()\n",
    "plt.axvline(mean, 0,0.41, color='r', linestyle='--')\n",
    "\n",
    "# #https://stackoverflow.com/questions/51417483/mean-median-mode-lines-showing-only-in-last-graph-in-seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw= {\"height_ratios\": (0.2, 1)})\n",
    "mean=df_dev[\"quality\"].mean()\n",
    "#median=df_dev[\"quality\"].median()\n",
    "#mode=df_dev[\"quality\"].mode().get_values()[0]\n",
    "\n",
    "sns.boxplot(df_dev[\"quality\"], ax=ax_box, color='cornflowerblue', saturation=1)\n",
    "ax_box.axvline(mean, color='r', linestyle='--', label='mean')\n",
    "#ax_box.axvline(median, color='g', linestyle='-')\n",
    "#ax_box.axvline(mode, color='b', linestyle='-')\n",
    "\n",
    "sns.distplot(df[\"quality\"], ax=ax_hist,  color='cornflowerblue')\n",
    "ax_hist.axvline(mean, color='r', linestyle='--', label='mean')\n",
    "# ax_hist.axvline(median, color='g', linestyle='-')\n",
    "# ax_hist.axvline(mode, color='b', linestyle='-')\n",
    "\n",
    "plt.legend()\n",
    "ax_box.set(xlabel='')\n",
    "#ax.set_xticks(np.arange(0,130000,20000))\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#f.savefig(\"qualityDensity.pdf\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_dev['description'].value_counts().values>1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_unique_description = df_dev['description'].value_counts()[df_dev['description'].value_counts().values > 1].index\n",
    "\n",
    "df_description_mask=df_dev['description'].isin(not_unique_description)\n",
    "df_description = df_dev[df_description_mask]\n",
    "#df_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_duplicate_descr = [not elem for elem in df_description_mask]\n",
    "df_dev = df_dev[mask_duplicate_descr]\n",
    "#df_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description_length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dev[\"Description_Length\"] = [len(desc.split()) for desc in df_dev['description']]\n",
    "# df_eval[\"Description_Length\"] = [len(desc.split()) for desc in df_eval['description']]\n",
    "# df[\"Description_Length\"] = [len(desc.split()) for desc in df['description']]\n",
    "\n",
    "# df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# sns.set_theme(style=\"ticks\")\n",
    "\n",
    "\n",
    "# sns.set_context(\"paper\", font_scale=1.5) \n",
    "\n",
    "# ax = sns.jointplot(x=df_dev['quality'], y=df_dev['Description_Length'], kind=\"hex\", color=\"#4CB391\")\n",
    "# ax.set_ylim(0,100)\n",
    "# ax.savefig(\"description_length.pdf\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_rho = np.corrcoef(df_dev['quality'], df_dev['Description_Length'])\n",
    "\n",
    "# print(my_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns[0:8] #non prendo la colonna quality e descr_length\n",
    "\n",
    "for column in columns:\n",
    "    df[column] = df[column].str.lower().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    \n",
    "for column in columns:\n",
    "    df_dev[column] = df_dev[column].str.lower().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    \n",
    "for column in columns:\n",
    "    df_eval[column] = df_eval[column].str.lower().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = df_dev.drop(labels = ['description','quality'], axis=1)#.values\n",
    "y_dev = df_dev['quality']#.values[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = df_eval.drop(labels = ['description'], axis=1)#.values\n",
    "X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dev1 = df_dev.drop(labels = ['description','region_2','country'], axis=1)\n",
    "# df_dev1.drop_duplicates(inplace = True)\n",
    "# df_dev1\n",
    "# X_dev = df_dev1.drop(labels = ['quality'], axis=1)\n",
    "# y_dev = df_dev1['quality']\n",
    "# X_eval = df_eval.drop(labels = ['description','region_2', 'country'], axis=1)#.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# designation = df_dev['designation'].value_counts()\n",
    "\n",
    "# N_entries = 10  #we encode when winery category is at least 2 times frequent\n",
    "# mask = designation.values >= N_entries\n",
    "# top_frequent_designation=designation[mask].index\n",
    "\n",
    "# df_designation_mask=df_dev['designation'].isin(top_frequent_designation)\n",
    "# df['tf_winery']=df_dev['winery'][df_designation_mask]\n",
    "# df['tf_winery'].fillna(value='other',inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_to_encode, X_test_to_encode, y_train, y_test = train_test_split(X_dev, y_dev, train_size= 0.8, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TargetEncoder(cols=['designation','region_1','province','variety','winery', 'country','region_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = encoder.fit_transform(X_train_to_encode, y_train)\n",
    "X_test_encoded = encoder.transform(X_test_to_encode)\n",
    "\n",
    "X_dev_encoded = encoder.fit_transform(X_dev, y_dev)\n",
    "X_eval_encoded = encoder.transform(X_eval)\n",
    "\n",
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from scipy.sparse import hstack\n",
    "# X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF_norm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF_matrix_test=v.transform(X_test_to_encode['description'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_encoded = hstack((X_test_encoded.values.astype(float), TFIDF_matrix_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols_to_norm = [0,1,2,3,4,5,6]\n",
    "# X_train_encoded[cols_to_norm] = X_train_encoded[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "# X_test_encoded[cols_to_norm] = X_train_encoded[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "\n",
    "# X_dev_encoded.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_estimators=128, max_features='sqrt')\n",
    "reg.fit(X_train_encoded, y_train)\n",
    "y_hat = reg.predict(X_test_encoded)\n",
    "y_hat.mean(), y_hat.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train_encoded.columns\n",
    "sorted(zip(feature_names, reg.feature_importances_), key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['winery','designation','region_1','variety','province','country','region_2']\n",
    "importance = [0.660, 0.148, 0.077, 0.0613, 0.028, 0.017, 0.009]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.set(rc={'figure.figsize':(6,4)})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.5) \n",
    "\n",
    "ax.set(xlabel='Feature importance')\n",
    "ax.set(ylabel='Features')\n",
    "sns.color_palette(\"pastel\")\n",
    "\n",
    "sns.barplot(x=importance, y=names)\n",
    "\n",
    "#fig.savefig(\"featureImportance.pdf\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = KNeighborsRegressor(n_neighbors=50, weights='distance', algorithm='auto')\n",
    "reg.fit(X_train_encoded, y_train)\n",
    "y_hat = reg.predict(X_test_encoded)\n",
    "r2_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVR\n",
    "# reg = LinearSVR(max_iter=10000)\n",
    "# reg.fit(X_train_encoded, y_train)\n",
    "# y_hat = reg.predict(X_test_encoded)\n",
    "# y_hat.mean(), y_hat.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_score(y_test,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg = MLPRegressor(hidden_layer_sizes=(64,128,128,128,256,256,256,128),\n",
    "#                    verbose=True, random_state=9, early_stopping=True)\n",
    "# reg.fit(X_dev_encoded, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = make_pipeline(PolynomialFeatures(5), Ridge(alpha=0.5, tol=0.2))\n",
    "reg.fit(X_train_encoded, y_train)\n",
    "y_hat = reg.predict(X_test_encoded)\n",
    "y_hat.mean(), y_hat.std()\n",
    "r2_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "params = {\n",
    "    #\"max_depth\": [None], #None\n",
    "    #\"min_impurity_decrease\": [0], #0\n",
    "    #\"criterion\": ['mse'] #mse\n",
    "    \"n_estimators\": [128,256,512],\n",
    "    \"max_features\": [\"sqrt\"],  #ho levato \"auto\" che sembra il meno performante, ho levato log2 perchè funziona uguale a sqrt ma ci mette più tempo\n",
    "    #\"max_leaf_nodes\" : [9000, 10000, 11000,], #funziona meglio di None\n",
    "    #\"min_samples_split\": [2,3], #2\n",
    "    #\"min_samples_leaf\": [1,2], #1\n",
    "    \"random_state\": [42], # always use the samet random seed\n",
    "    \"n_jobs\": [-1], # for parallelization\n",
    "}\n",
    "\n",
    "r2s = []\n",
    "for config in ParameterGrid(params):\n",
    "    reg = RandomForestRegressor(**config)\n",
    "    reg.fit(X_train_encoded, y_train)\n",
    "    r2s.append(r2_score(y_test, reg.predict(X_test_encoded)))\n",
    "    print(config, r2_score(y_test, reg.predict(X_test_encoded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "params = {\n",
    "    \"n_neighbors\" : [25,30,35,40,45,50,55,60], #30\n",
    "    \"weights\" : [\"uniform\", \"distance\"], #distance\n",
    "    \"p\" : [1,2], #1\n",
    "    \"n_jobs\" : [-1]\n",
    "}\n",
    "\n",
    "r2s = []\n",
    "for config in ParameterGrid(params):\n",
    "    reg = KNeighborsRegressor(**config)\n",
    "    reg.fit(X_train_encoded, y_train)\n",
    "    r2s.append(r2_score(y_test, reg.predict(X_test_encoded)))\n",
    "    print(config, r2_score(y_test, reg.predict(X_test_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.feature_extraction import text\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# corpus = df_dev[\"description\"].values\n",
    "# Y = df_dev[\"quality\"].values\n",
    "\n",
    "# customStopWords = text.ENGLISH_STOP_WORDS.union(['wine', '2009', '2010','2011', '2012', '2013', '2014', '2015','2016', '2017', '2018',\n",
    "#                                                  '2019', '2020', '2021', '2022','2023', '2024', '2025', '2030', '100', '10', '12',\n",
    "#                                                  '14', '15', '20', '25', '30','40', '50', '60', '70', '90'])\n",
    "\n",
    "# CV = CountVectorizer(stop_words=customStopWords, max_features=20, ngram_range=(1,2))\n",
    "# X = CV.fit_transform(corpus) #Let's be careful here, X is a sparse Matrix\n",
    "\n",
    "# print(\"Number of entries (rows):\", X.shape[0],\\\n",
    "#       \"\\nNumber of features (columns):\", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_array = X.toarray() #Convert X from a sparse matrix to a usual matrix\n",
    "\n",
    "# inverted_dict = dict([[v,k] for k,v in CV.vocabulary_.items()]) # {X_array column index: \"word\"}\n",
    "# final_dict = {} # {\"word\": total number of instances }\n",
    "\n",
    "# for x in range(len(X_array[0,:])): #Fill the final dict\n",
    "#     final_dict[inverted_dict[x]]=np.sum(X_array[:,x]) \n",
    "\n",
    "# print(\"20 most frequent words:\",sorted(final_dict.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)[0:20]) #Display of the final dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.scatterplot(y_test.ravel(),y_hat.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding (X_train_to_encode, y_train, X_test_to_encode, y_test):\n",
    "    encoder = TargetEncoder()\n",
    "    X_train_encoded = encoder.fit_transform(X_train_to_encode, y_train)\n",
    "    X_test_encoded = encoder.transform(X_test_to_encode)\n",
    "    return X_train_encoded, X_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test(X, y):\n",
    "    X_train_to_encode, X_test_to_encode, y_train, y_test = train_test_split(X_dev, y_dev, test_size= 0.2, shuffle=True, random_state=42)\n",
    "    X_train, X_test = target_encoding(X_train_to_encode,y_train,X_test_to_encode,y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, model, model_name):\n",
    "    X_train, X_test, y_train, y_test = generate_train_test(X, y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    return mean_squared_error(y_test, y_hat), r2_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "degree = 5\n",
    "models = [\n",
    "    make_pipeline(PolynomialFeatures(degree), Lasso(alpha=0.5, tol=0.2)),\n",
    "    make_pipeline(PolynomialFeatures(degree), Ridge(alpha=0.5, tol=0.2)),\n",
    "    LinearRegression(),\n",
    "    Ridge(random_state=42),\n",
    "    MLPRegressor(),\n",
    "    RandomForestRegressor(n_estimators=10),\n",
    "    KNeighborsRegressor()\n",
    "\n",
    "]\n",
    "names = [\n",
    "    'polyn+lasso',\n",
    "    'polyn+ridge',\n",
    "    'linreg',\n",
    "    'ridge',\n",
    "    'mlp_standard',\n",
    "    'rf',\n",
    "    'KNN',\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = PrettyTable()\n",
    "t.field_names = ['model', 'MSE', 'R2']\n",
    "for model, name in zip(models, names):\n",
    "    mse, r2 = evaluate_model(X_dev, y_dev, model, name)\n",
    "    t.add_row([name, mse, r2])\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(stop_words=\"english\", binary=True, use_idf=False, norm=False)\n",
    "# wpm = vectorizer.fit_transform(df_dev[\"description\"])\n",
    "# N = 150\n",
    "# freq = sorted(zip(vectorizer.get_feature_names(), wpm.sum(axis=0).tolist()[0]), key=lambda x: x[1], reverse=True)[:N]\n",
    "\n",
    "# # mask to be used to filter columns in wpm (only keeps the ones for the 100 most␣frequent words)\n",
    "# words = [ word for word, _ in freq ]\n",
    "# mask = [ w in words for w in vectorizer.get_feature_names() ]\n",
    "# words_ = [ w for w in vectorizer.get_feature_names() if w in words ]\n",
    "# words_df = pd.DataFrame(data=wpm[:, np.array(mask)].toarray(), columns=[f\"word_{word}\" for word in words_], index=df_dev.index)\n",
    "\n",
    "# # Only encode \"room_type\"\n",
    "# df_dev = pd.get_dummies(df, columns=['room_type'])\n",
    "# df_dev = df_dev.join(pd.DataFrame(data=wpm[:, np.array(mask)].toarray(), columns=[f\"word_{word}\" for word in words_], index=df_dev.index))\n",
    "# # discard \"neighbourhood\" and \"neighbourhood_group\"\n",
    "# df_dropped = df_1h.drop(columns=[\"neighbourhood_group\",\"neighbourhood\", \"name\", \"host_name\", \"last_review\"])\n",
    "# df_dropped[\"id\"] = df_dropped.index\n",
    "# train_valid_mask = ~df_dropped[\"price\"].isna()\n",
    "# feature_names = df_dropped[train_valid_mask].drop(columns=[\"price\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = df_dev.columns\n",
    "\n",
    "# for column in columns:\n",
    "#     category_number = df_dev[column].value_counts()\n",
    "#     print(column ,':', (category_number<=1).sum(), '/', len(df_dev[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "reg = RandomForestRegressor(n_estimators=1028, max_leaf_nodes= None, max_features = 'sqrt' )\n",
    "reg.fit(X_dev_encoded, y_dev)\n",
    "\n",
    "y_final_pred = reg.predict(X_eval_encoded)\n",
    "pd.DataFrame(y_final_pred).to_csv(\"output.csv\", index_label=\"Id\", header=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from scipy.sparse import hstack, vstack\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>A creamed pear wine, with an attractive tang o...</td>\n",
       "      <td>Brut Blanc de Blancs</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Crémant d'Alsace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pinot Blanc</td>\n",
       "      <td>Lucien Albrecht</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>Simple and dry, this Cabernet has modest black...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California</td>\n",
       "      <td>Paso Robles</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Castle Rock</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>This lovely wine captures the floral, perfumed...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Gewürztraminer</td>\n",
       "      <td>Château Bianca</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>The aromas are the thing here, as so often wit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Touriga Nacional</td>\n",
       "      <td>Herdade do Esporão</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Italy</td>\n",
       "      <td>This is an interesting, outright strange wine ...</td>\n",
       "      <td>Natì</td>\n",
       "      <td>Southern Italy</td>\n",
       "      <td>Pompeiano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coda di Volpe</td>\n",
       "      <td>Sorrentino</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120730</th>\n",
       "      <td>France</td>\n",
       "      <td>Moët's style, with its delicious forward fruit...</td>\n",
       "      <td>Brut</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>Champagne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Champagne Blend</td>\n",
       "      <td>Moët &amp; Chandon</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120732</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is soft, young and fruity, with a dominat...</td>\n",
       "      <td>PV Ruby Port Collections</td>\n",
       "      <td>Port</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port</td>\n",
       "      <td>Barão de Vilar</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120733</th>\n",
       "      <td>US</td>\n",
       "      <td>Showing ripe peach, pineapple and honeysuckle ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California</td>\n",
       "      <td>Yountville</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Liparita</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120735</th>\n",
       "      <td>US</td>\n",
       "      <td>A first release from this new Walla Walla wine...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Walla Walla Valley (WA)</td>\n",
       "      <td>Columbia Valley</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Delmas</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120738</th>\n",
       "      <td>US</td>\n",
       "      <td>This is the winery's fruitier, more accessible...</td>\n",
       "      <td>Les Cotes de l'Ouest</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "      <td>California Other</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Terre Rouge</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85028 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         country                                        description  \\\n",
       "0         France  A creamed pear wine, with an attractive tang o...   \n",
       "1             US  Simple and dry, this Cabernet has modest black...   \n",
       "2             US  This lovely wine captures the floral, perfumed...   \n",
       "3       Portugal  The aromas are the thing here, as so often wit...   \n",
       "4          Italy  This is an interesting, outright strange wine ...   \n",
       "...          ...                                                ...   \n",
       "120730    France  Moët's style, with its delicious forward fruit...   \n",
       "120732  Portugal  This is soft, young and fruity, with a dominat...   \n",
       "120733        US  Showing ripe peach, pineapple and honeysuckle ...   \n",
       "120735        US  A first release from this new Walla Walla wine...   \n",
       "120738        US  This is the winery's fruitier, more accessible...   \n",
       "\n",
       "                     designation        province                 region_1  \\\n",
       "0           Brut Blanc de Blancs          Alsace         Crémant d'Alsace   \n",
       "1                            NaN      California              Paso Robles   \n",
       "2                            NaN          Oregon        Willamette Valley   \n",
       "3                            NaN      Alentejano                      NaN   \n",
       "4                           Natì  Southern Italy                Pompeiano   \n",
       "...                          ...             ...                      ...   \n",
       "120730                      Brut       Champagne                Champagne   \n",
       "120732  PV Ruby Port Collections            Port                      NaN   \n",
       "120733                       NaN      California               Yountville   \n",
       "120735                       NaN      Washington  Walla Walla Valley (WA)   \n",
       "120738      Les Cotes de l'Ouest      California               California   \n",
       "\n",
       "                 region_2             variety              winery  quality  \n",
       "0                     NaN         Pinot Blanc     Lucien Albrecht     45.0  \n",
       "1           Central Coast  Cabernet Sauvignon         Castle Rock     31.0  \n",
       "2       Willamette Valley      Gewürztraminer      Château Bianca     35.0  \n",
       "3                     NaN    Touriga Nacional  Herdade do Esporão     41.0  \n",
       "4                     NaN       Coda di Volpe          Sorrentino     37.0  \n",
       "...                   ...                 ...                 ...      ...  \n",
       "120730                NaN     Champagne Blend      Moët & Chandon     59.0  \n",
       "120732                NaN                Port      Barão de Vilar     42.0  \n",
       "120733               Napa          Chardonnay            Liparita     46.0  \n",
       "120735    Columbia Valley               Syrah              Delmas     58.0  \n",
       "120738   California Other               Syrah         Terre Rouge     40.0  \n",
       "\n",
       "[85028 rows x 9 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = pd.read_csv('dev.tsv', sep='\\t')\n",
    "#df_dev.drop_duplicates(inplace = True)\n",
    "df_dev=df_dev[df_dev['quality']>=0]\n",
    "\n",
    "df_eval = pd.read_csv('eval.tsv', sep='\\t')\n",
    "\n",
    "df = pd.concat([df_dev, df_eval], sort=False, ignore_index=True)\n",
    "len(df_dev)\n",
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns[0:8] #non prendo la colonna quality e descr_length\n",
    "\n",
    "for column in columns:\n",
    "    df[column] = df[column].str.lower().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    \n",
    "for column in columns:\n",
    "    df_dev[column] = df_dev[column].str.lower().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    \n",
    "for column in columns:\n",
    "    df_eval[column] = df_eval[column].str.lower().str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_unique_description = df_dev['description'].value_counts()[df_dev['description'].value_counts().values > 1].index\n",
    "\n",
    "df_description_mask=df_dev['description'].isin(not_unique_description)\n",
    "df_description = df_dev[df_description_mask]\n",
    "#df_description\n",
    "mask_duplicate_descr = [not elem for elem in df_description_mask]\n",
    "df_dev = df_dev[mask_duplicate_descr]\n",
    "#df_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85028x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1889731 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "v = TfidfVectorizer(stop_words='english',ngram_range=(1, 2), max_features = 2000)\n",
    "TFIDF_matrix = v.fit_transform(df_dev['description'])\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "TFIDF_norm = scaler.fit_transform(TFIDF_matrix)\n",
    "TFIDF_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Winery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85028x9663 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 85028 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winery = df_dev['winery'].value_counts()\n",
    "\n",
    "N_entries = 2  #we encode when winery category is at least 2 times frequent\n",
    "mask = winery.values >= N_entries\n",
    "top_frequent_winery=winery[mask].index\n",
    "\n",
    "df_winery_mask=df_dev['winery'].isin(top_frequent_winery)\n",
    "df_dev['tf_winery']=df_dev['winery'][df_winery_mask]\n",
    "df_dev['tf_winery'].fillna(value='other',inplace=True) \n",
    "\n",
    "enc1 = OneHotEncoder(handle_unknown='ignore')\n",
    "df_1h_winery=enc1.fit_transform(df_dev['tf_winery'].values.reshape(-1, 1)) #with reshape we have a column vector\n",
    "df_1h_winery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = df_dev['designation'].value_counts()\n",
    "\n",
    "N_entries = 2  #we encode when winery category is at least 2 times frequent\n",
    "mask = designation.values >= N_entries\n",
    "top_frequent_designation=designation[mask].index\n",
    "\n",
    "df_designation_mask=df_dev['designation'].isin(top_frequent_designation)\n",
    "df_dev['tf_designation']=df_dev['designation'][df_designation_mask]\n",
    "df_dev['tf_designation'].fillna(value='other',inplace=True) \n",
    "\n",
    "enc2 = OneHotEncoder(handle_unknown='ignore')\n",
    "df_1h_designation=enc2.fit_transform(df_dev['tf_designation'].values.reshape(-1, 1)) #with reshape we have a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85028x8876 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 85028 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1h_designation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85028x552 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 85028 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_1 = df_dev['region_1'].value_counts()\n",
    "\n",
    "N_entries = 10  #we encode when winery category is at least 2 times frequent\n",
    "mask = region_1.values >= N_entries\n",
    "top_frequent_region_1=region_1[mask].index\n",
    "\n",
    "\n",
    "df_region_1_mask=df_dev['region_1'].isin(top_frequent_region_1)\n",
    "df_dev['tf_region_1']=df_dev['region_1'][df_region_1_mask]\n",
    "df_dev['tf_region_1'].fillna(value='other',inplace=True) \n",
    "\n",
    "enc3 = OneHotEncoder(handle_unknown='ignore')\n",
    "df_1h_region_1=enc3.fit_transform(df_dev['tf_region_1'].values.reshape(-1, 1)) #with reshape we have a column vector\n",
    "df_1h_region_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variety = df_dev['variety'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_entries = 5  #we encode when winery category is at least 2 times frequent\n",
    "# mask = variety.values >= N_entries\n",
    "# top_frequent_variety=variety[mask].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_variety_mask=df_dev['variety'].isin(top_frequent_variety)\n",
    "# df_dev['tf_variety']=df_dev['variety'][df_variety_mask]\n",
    "# df_dev['tf_variety'].fillna(value='other',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# df_1h_variety=enc.fit_transform(df_dev['tf_variety'].values.reshape(-1, 1)) #with reshape we have a column vector\n",
    "# df_1h_variety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alsace</td>\n",
       "      <td>pinot blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>california</td>\n",
       "      <td>cabernet sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oregon</td>\n",
       "      <td>gewurztraminer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alentejano</td>\n",
       "      <td>touriga nacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>southern italy</td>\n",
       "      <td>coda di volpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115209</th>\n",
       "      <td>california</td>\n",
       "      <td>bordeaux-style red blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115210</th>\n",
       "      <td>california</td>\n",
       "      <td>cabernet franc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115211</th>\n",
       "      <td>california</td>\n",
       "      <td>g-s-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115212</th>\n",
       "      <td>polkadraai hills</td>\n",
       "      <td>chenin blanc-sauvignon blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115213</th>\n",
       "      <td>california</td>\n",
       "      <td>riesling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115214 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                province                       variety\n",
       "0                 alsace                   pinot blanc\n",
       "1             california            cabernet sauvignon\n",
       "2                 oregon                gewurztraminer\n",
       "3             alentejano              touriga nacional\n",
       "4         southern italy                 coda di volpe\n",
       "...                  ...                           ...\n",
       "115209        california      bordeaux-style red blend\n",
       "115210        california                cabernet franc\n",
       "115211        california                         g-s-m\n",
       "115212  polkadraai hills  chenin blanc-sauvignon blanc\n",
       "115213        california                      riesling\n",
       "\n",
       "[115214 rows x 2 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quality = df_dev['quality']\n",
    "\n",
    "df = pd.concat([df_dev, df_eval], sort=False, ignore_index=True)\n",
    "\n",
    "df.drop(labels=['country','winery','description','designation','quality','region_2','region_1', 'tf_winery','tf_designation','tf_region_1'],axis=1,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rows = df_dev.shape[0]\n",
    "\n",
    "df_1h_total = pd.get_dummies(df,sparse=True)   #one hot encoding of the categorical attribute\n",
    "df_1h_total\n",
    "\n",
    "df_1h = df_1h_total.values[:dev_rows, :]\n",
    "df_1h_eval =df_1h_total.values[dev_rows:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85028x22178 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2314868 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1h = hstack([df_1h, df_1h_winery, df_1h_designation, df_1h_region_1, TFIDF_norm])\n",
    "df_1h = df_1h.tocsr()  #convert this matrix to Compressed Sparse Row format\n",
    "df_1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dev=df_1h[:dev_rows,:]\n",
    "# y_dev=df_quality[:dev_rows]\n",
    "\n",
    "# X_eval=df_1h[dev_rows:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hold out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_valid, y_train, y_valid = train_test_split(df_1h,df_quality, test_size= 0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 98.02250689\n",
      "Validation score: 0.653423\n",
      "Iteration 2, loss = 19.07863574\n",
      "Validation score: 0.709549\n",
      "Iteration 3, loss = 13.82015367\n",
      "Validation score: 0.729274\n",
      "Iteration 4, loss = 10.38585379\n",
      "Validation score: 0.732984\n",
      "Iteration 5, loss = 7.90194386\n",
      "Validation score: 0.731270\n",
      "Iteration 6, loss = 5.97339059\n",
      "Validation score: 0.728530\n",
      "Iteration 7, loss = 4.48197320\n",
      "Validation score: 0.721087\n",
      "Iteration 8, loss = 3.36111867\n",
      "Validation score: 0.710010\n",
      "Iteration 9, loss = 2.62460121\n",
      "Validation score: 0.706913\n",
      "Iteration 10, loss = 2.12615042\n",
      "Validation score: 0.709532\n",
      "Iteration 11, loss = 1.80857846\n",
      "Validation score: 0.703490\n",
      "Iteration 12, loss = 1.56125003\n",
      "Validation score: 0.699985\n",
      "Iteration 13, loss = 1.41603043\n",
      "Validation score: 0.695938\n",
      "Iteration 14, loss = 1.32146562\n",
      "Validation score: 0.698453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, hidden_layer_sizes=(256, 256),\n",
       "             random_state=42, verbose=True)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = MLPRegressor(activation='tanh', \n",
    "                   #hidden_layer_sizes=(256, 256),\n",
    "                   random_state=42,\n",
    "                   validation_fraction=0.1,\n",
    "                                verbose=True,\n",
    "                                early_stopping=True)\n",
    "reg.fit(df_1h, df_quality)\n",
    "# y_pred = reg.predict(X_valid) \n",
    " \n",
    "# r2 = r2_score(y_valid, y_pred)\n",
    "# print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = reg.predict(X_valid)\n",
    "# r2 = r2_score(y_valid, y_pred)\n",
    "# print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30186x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 670620 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF_matrix_eval = v.transform(df_eval['description'])\n",
    "\n",
    "TFIDF_norm_eval = scaler.transform(TFIDF_matrix_eval)\n",
    "TFIDF_norm_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30186x9663 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 30186 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_winery_mask_eval=df_eval['winery'].isin(top_frequent_winery)\n",
    "df_eval['tf_winery']=df_eval['winery'][df_winery_mask_eval]\n",
    "df_eval['tf_winery'].fillna(value='other',inplace=True) \n",
    "\n",
    "df_1h_winery_eval=enc1.transform(df_eval['tf_winery'].values.reshape(-1, 1)) #with reshape we have a column vector\n",
    "df_1h_winery_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30186x8876 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 23063 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_designation_mask_eval=df_eval['designation'].isin(top_frequent_winery)\n",
    "df_eval['tf_designation']=df_eval['designation'][df_winery_mask_eval]\n",
    "df_eval['tf_designation'].fillna(value='other',inplace=True) \n",
    "\n",
    "df_1h_designation_eval=enc2.transform(df_eval['tf_designation'].values.reshape(-1, 1)) #with reshape we have a column vector\n",
    "df_1h_designation_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30186x552 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 30186 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_region_1_mask_eval=df_eval['region_1'].isin(top_frequent_region_1)\n",
    "df_eval['tf_region_1']=df_eval['region_1'][df_region_1_mask_eval]\n",
    "df_eval['tf_region_1'].fillna(value='other',inplace=True) \n",
    "\n",
    "df_1h_region_1_eval=enc3.transform(df_eval['tf_region_1'].values.reshape(-1, 1)) #with reshape we have a column vector\n",
    "df_1h_region_1_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30186, 1087)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1h_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30186x22178 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 814427 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1h_eval = hstack([df_1h_eval, df_1h_winery_eval, df_1h_designation_eval, df_1h_region_1_eval, TFIDF_norm_eval])\n",
    "df_1h_eval = df_1h_eval.tocsr()\n",
    "df_1h_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "y_final_pred = reg.predict(df_1h_eval)\n",
    "pd.DataFrame(y_final_pred).to_csv(\"output.csv\", index_label=\"Id\", header=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 9, 'epsilon': 2, 'fit_intercept': True, 'max_iter': 6000}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "reg = LinearSVR()\n",
    "param_grid = {'epsilon':[2], 'C':[7,8,9], 'fit_intercept':[True], 'max_iter' : [5000,6000]} #,'max_iter':[1000,2000,3000,4000,5000,6000]\n",
    "gridsearch = GridSearchCV(reg, param_grid, scoring='r2', cv=5)\n",
    "\n",
    "gridsearch.fit(df_1h, df_quality)\n",
    "print(gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737711425960917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "reg = LinearSVR(epsilon=2, C=7, max_iter=5000)\n",
    "scores = cross_val_score(reg, df_1h, df_quality, cv=5, scoring='r2')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "reg.fit(df_1h,df_quality)\n",
    "y_final_pred = reg.predict(df_1h_eval)\n",
    "pd.DataFrame(y_final_pred).to_csv(\"output.csv\", index_label=\"Id\", header=[\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
